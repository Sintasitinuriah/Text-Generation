{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172fddc4",
   "metadata": {},
   "source": [
    "#### Text Generation Using LSTM\n",
    "**LSTMs** adalah jenis jaringan saraf tiruan yang sangat cocok untuk tugas-tugas yang melibatkan data berurutan, seperti pembangkitan teks. Mereka sangat berguna karena dapat mengingat ketergantungan jangka panjang dalam data, yang sangat penting saat menangani teks yang seringkali memiliki konteks yang melintasi beberapa kata atau kalimat.\n",
    "\n",
    "----\n",
    "Implementasi dalam Python **Text Generation** merupakan bagian dari Pemrosesan Bahasa Alami (NLP) dengan proses melatih model pada dataset yang melibatkan sejumlah besar data teks, dan model LSTM akan menggunakannya untuk melatih model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9acef",
   "metadata": {},
   "source": [
    "#### Implementasi dengan python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065e289",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Import Library\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffdbb8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/train.csv')\n",
    "text = \" \".join(df['text'].dropna().astype(str)).lower()\n",
    "\n",
    "print(f'Total characters in text: {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9d28d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'Vocabulary size: {len(vocab)}')\n",
    "\n",
    "char2idx = {c: i for i, c in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ee9cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "seq_length = 100 \n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    return chunk[:-1], chunk[1:]\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58dafe5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 64\n",
    "rnn_units = 128\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_shape=(None,)),\n",
    "    tf.keras.layers.LSTM(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c747fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "history = model.def generate_text(model, start_string, num_generate=100, temperature=1.0):\n",
    "    input_eval = [char2idx.get(s, 0) for s in start_string.lower()]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    model.layers[1].reset_states()\n",
    "\n",
    "    for _ in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0) / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n",
    "\n",
    "\n",
    "print(generate_text(model, start_string=\"The \", num_generate=200, temperature=0.8))fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d7b18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
